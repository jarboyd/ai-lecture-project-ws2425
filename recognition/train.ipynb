{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4d456a5178058",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pip install tensorflow pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2679b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "import PIL.Image\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f763301-09a6-4ec0-9e04-73200a16a60d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T16:37:57.130361Z",
     "start_time": "2025-02-11T16:37:53.591031Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size = (64, 64)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Datasets/GTSRB/Final_Training/Images_Converted\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Datasets/GTSRB/Final_Training/Images_Converted\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a853eff0-4774-4f95-b153-c3111762ae5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T16:38:17.816767Z",
     "start_time": "2025-02-11T16:38:17.221509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a0970f-5e24-4741-967a-cd34bee0a243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T16:38:20.065378Z",
     "start_time": "2025-02-11T16:38:20.058003Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179f5ce-8082-4f90-bdd3-c63036b0885a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T16:38:22.965538Z",
     "start_time": "2025-02-11T16:38:22.725598Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "611c5d6b-f44b-459f-a7bb-01a5498897d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T16:38:41.230135Z",
     "start_time": "2025-02-11T16:38:41.225068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c325bdc1-2c58-4677-a403-102bc28d4004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T16:38:46.075708Z",
     "start_time": "2025-02-11T16:38:46.070846Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testImage(file, model_):\n",
    "    img = PIL.Image.open(file).resize(image_size)\n",
    "\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model_.predict(img_array, verbose=0)\n",
    "    \n",
    "    c = -1\n",
    "    v = -1\n",
    "    for i in range(len(predictions[0])):\n",
    "        if predictions[0][i] > v:\n",
    "            v = predictions[0][i]\n",
    "            c = i\n",
    "\n",
    "    return (c, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e04523-4fe7-49e0-9c7f-2a45e67d6046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T16:38:48.603275Z",
     "start_time": "2025-02-11T16:38:48.207812Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=input_shape, kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    test_datagen = ImageDataGenerator()\n",
    "\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    lr_scheduler = ReduceLROnPlateau(factor=0.1, patience=5)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09676743-e6c1-4dde-b6f5-ec0aaae7a6fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T16:41:12.702852Z",
     "start_time": "2025-02-11T16:39:00.204063Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"./save/save_at_{epoch}.h5\"),\n",
    "    EarlyStopping(patience=3),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=2)\n",
    "]\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "epochs = 1\n",
    "model.fit(\n",
    "    train_ds, \n",
    "    epochs=epochs, \n",
    "    callbacks=callbacks, \n",
    "    validation_data=val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede924b6-ceb0-48b2-9de4-25cea063da1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T18:15:08.451334Z",
     "start_time": "2025-02-11T18:15:08.312984Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "test_all_folders = False\n",
    "folders_to_test = ['1']  # Only relevant if test_all_folders is False\n",
    "\n",
    "model_path = './save/save_at_24.keras'\n",
    "print(f\"Using model: {model_path}\")\n",
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "correct = 0\n",
    "mean_quality = 0\n",
    "count = 0\n",
    "error = []\n",
    "\n",
    "print(\"Testing...\")\n",
    "\n",
    "for class_id in os.listdir(\"Datasets/GTSRB/Final_Test/Sorted_Images\"):\n",
    "    class_folder = os.path.join(\"Datasets/GTSRB/Final_Test/Sorted_Images\", class_id)\n",
    "    \n",
    "    if os.path.isdir(class_folder) and (test_all_folders or class_id in folders_to_test):\n",
    "        print(f\"testing folder {class_id}\")  # Printing current folder (class)\n",
    "\n",
    "        folder_correct = 0\n",
    "        folder_mean_quality = 0\n",
    "        folder_count = 0\n",
    "        folder_error = []\n",
    "\n",
    "        for img_name in os.listdir(class_folder):\n",
    "            if img_name.endswith('.jpg'):\n",
    "                img_path = os.path.join(class_folder, img_name)\n",
    "                \n",
    "                true_class = int(class_id)\n",
    "\n",
    "                predicted_class, confidence = testImage(img_path, model)\n",
    "\n",
    "                folder_count += 1\n",
    "                folder_mean_quality += confidence\n",
    "\n",
    "                if predicted_class == true_class:\n",
    "                    folder_correct += 1\n",
    "                else:\n",
    "                    folder_error.append(img_path)\n",
    "                    print(f\"Error: {img_path} predicted class {predicted_class}, actual class {true_class}, confidence: {confidence * 100:.2f}%\")\n",
    "\n",
    "        if folder_count > 0:\n",
    "            print(f\"\\nFolder {class_id} results:\")\n",
    "            print(f\"Mean quality: {100 * (folder_mean_quality / folder_count):.2f}%, Correct: {folder_correct}/{folder_count} ({100 * folder_correct / folder_count:.2f}%), Wrong: {folder_count - folder_correct}/{folder_count} ({100 * (folder_count - folder_correct) / folder_count:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"No images were processed in folder {class_id}. Please check the directory.\")\n",
    "\n",
    "        correct += folder_correct\n",
    "        mean_quality += folder_mean_quality\n",
    "        count += folder_count\n",
    "        error.extend(folder_error)\n",
    "\n",
    "if count > 0:\n",
    "    print(f\"\\nGlobal results:\")\n",
    "    print(f\"Mean quality: {100 * (mean_quality / count):.2f}%, Correct: {correct}/{count} ({100 * correct / count:.2f}%), Wrong: {count - correct}/{count} ({100 * (count - correct) / count:.2f}%)\")\n",
    "else:\n",
    "    print(\"No images were processed. Please check the directory.\")\n",
    "\n",
    "if error:\n",
    "    print(\"\\nError files:\")\n",
    "    print(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
